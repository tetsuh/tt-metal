# SPDX-FileCopyrightText: Â© 2025 Tenstorrent AI ULC

# SPDX-License-Identifier: Apache-2.0

import os
from datetime import datetime

import cv2
import matplotlib.pyplot as plt
import numpy as np
import pytest
import torch
from loguru import logger

import ttnn
from models.demos.yolov9c.demo.demo_seg_utils import postprocess, preprocess
from models.demos.yolov9c.demo.demo_utils import load_coco_class_names, load_torch_model
from models.demos.yolov9c.tt import ttnn_yolov9c
from models.demos.yolov9c.tt.model_preprocessing import create_yolov9c_input_tensors, create_yolov9c_model_parameters
from models.experimental.yolo_evaluation.yolo_common_evaluation import save_yolo_predictions_by_model
from models.experimental.yolo_evaluation.yolo_evaluation_utils import LoadImages
from models.experimental.yolo_evaluation.yolo_evaluation_utils import postprocess as obj_postprocess
from models.utility_functions import disable_persistent_kernel_cache, run_for_wormhole_b0


def get_consistent_color(index):
    cmap = plt.get_cmap("tab20")
    color = cmap(index % 20)[:3]
    return tuple(int(c * 255) for c in color)


def save_seg_predictions_by_model(result, save_dir, image_path, model_name):
    os.makedirs(os.path.join(save_dir, model_name), exist_ok=True)
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    masks = result.masks.data.cpu().detach().numpy()
    mask_h, mask_w = masks.shape[1], masks.shape[2]

    image = cv2.resize(image, (mask_w, mask_h))
    overlay = image.copy()

    for i in range(len(masks)):
        mask = masks[i]
        color = get_consistent_color(i)
        mask_rgb = np.zeros_like(image, dtype=np.uint8)
        for c in range(3):
            mask_rgb[:, :, c] = (mask * color[c]).astype(np.uint8)

        mask_bool = mask.astype(bool)
        overlay[mask_bool] = (0.5 * overlay[mask_bool] + 0.5 * mask_rgb[mask_bool]).astype(np.uint8)

    overlay_bgr = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    out_path = os.path.join(save_dir, model_name, f"segmentation_{timestamp}.jpg")
    cv2.imwrite(out_path, overlay_bgr)
    logger.info(f"Saved to {out_path}")


@run_for_wormhole_b0()
@pytest.mark.parametrize("device_params", [{"l1_small_size": 32768}], indirect=True)
@pytest.mark.parametrize(
    "source",
    [
        "models/demos/yolov9c/demo/image.png",
        # "models/sample_data/huggingface_cat_image.jpg", # Uncomment to run the demo with another image.
    ],
)
@pytest.mark.parametrize(
    "model_type",
    [
        # "torch_model", # Uncomment to run the demo with torch model
        "tt_model",
    ],
)
@pytest.mark.parametrize(
    "use_weights_from_ultralytics",
    [
        "True",  # To run the demo with pre-trained weights
        # "False", # Uncomment to the run demo with random weights
    ],
)
@pytest.mark.parametrize(
    "model_task",
    [
        "segment",  # To run the demo for instance segmentation
        # "detect",  # To run the demo for Object Detection
    ],
)
def test_demo(device, source, model_type, use_weights_from_ultralytics, model_task, use_program_cache, reset_seeds):
    disable_persistent_kernel_cache()

    enable_segment = model_task == "segment"
    if model_type == "torch_model":
        model = load_torch_model(use_weights_from_ultralytics=use_weights_from_ultralytics, model_task=model_task)
        logger.info("Inferencing [Torch] Model")
    else:
        torch_input, ttnn_input = create_yolov9c_input_tensors(device)
        model = load_torch_model(use_weights_from_ultralytics=use_weights_from_ultralytics, model_task=model_task)
        parameters = create_yolov9c_model_parameters(model, torch_input, device=device)
        model = ttnn_yolov9c.YoloV9(device, parameters, enable_segment=enable_segment)
        logger.info("Inferencing [TTNN] Model")

    save_dir = "models/demos/yolov9c/demo/runs"
    dataset = LoadImages(path=source)
    names = load_coco_class_names()

    for batch in dataset:
        paths, im0s, s = batch
        im = preprocess(im0s, res=(640, 640))

        if model_type == "torch_model":
            preds = model(im)
            if enable_segment:
                results = postprocess(preds, im, im0s, batch)
                save_seg_predictions_by_model(results[0], save_dir, source, model_type)
            else:
                results = obj_postprocess(preds, im, im0s, batch, names)
                save_yolo_predictions_by_model(results[0], save_dir, source, model_type)

        else:
            img = torch.permute(im, (0, 2, 3, 1))
            ttnn_im = ttnn.from_torch(img, dtype=ttnn.bfloat16)

            preds = model(ttnn_im)
            preds[0] = ttnn.to_torch(preds[0], dtype=torch.float32)
            if enable_segment:
                detect1_out, detect2_out, detect3_out = [
                    ttnn.to_torch(tensor, dtype=torch.float32) for tensor in preds[1][0]
                ]

                mask = ttnn.to_torch(preds[1][1], dtype=torch.float32)
                proto = ttnn.to_torch(preds[1][2], dtype=torch.float32)
                proto = proto.reshape((1, 160, 160, 32)).permute((0, 3, 1, 2))

                preds[1] = [[detect1_out, detect2_out, detect3_out], mask, proto]

                results = postprocess(preds, im, im0s, batch)
                for i in range(len(results)):
                    save_seg_predictions_by_model(results[i], save_dir, paths[i], model_type)
            else:
                results = obj_postprocess(preds[0], im, im0s, batch, names)[0]
                save_yolo_predictions_by_model(results, save_dir, source, model_type)

    logger.info("Inference done")
